# Stroke Prediction Analysis - Results Summary

## Overview
This document summarizes the results and outputs generated by the `stroke_prediction_full_analysis.ipynb` notebook.

---

## ğŸ“Š Generated Visualizations (12 Plots)

All plots are saved in the `plots/` folder as high-resolution PNG files (300 DPI):

1. **01_target_distribution.png** - Shows the class imbalance (Healthy vs Stroke)
2. **02_correlation_heatmap.png** - Correlation matrix highlighting stroke correlations
3. **03_outliers_before_winsorization.png** - Boxplots showing outliers before treatment
4. **04_outliers_after_winsorization.png** - Boxplots showing outliers after Winsorization
5. **05_violin_plots_numerical_features.png** - Distribution of age, glucose, and BMI by stroke status
6. **06_roc_auc_curves.png** - Combined ROC-AUC curves for all 5 models
7. **07_precision_recall_curves.png** - Combined Precision-Recall curves (better for imbalanced data)
8. **08_confusion_matrices_top2.png** - Normalized confusion matrices for top 2 models
9. **09_calibration_curve.png** - Probability calibration for the best model
10. **10_feature_importance.png** - Top 15 most important features from best tree model
11. **11_shap_summary_bar.png** - SHAP feature importance (bar plot)
12. **12_shap_summary_detailed.png** - SHAP summary plot showing feature impact

---

## ğŸ“ˆ Model Performance Metrics

The notebook evaluates **5 machine learning models**:

1. **Logistic Regression** (Baseline)
2. **Support Vector Machine (SVM)**
3. **Random Forest** (Bagging)
4. **XGBoost** (Gradient Boosting)
5. **LightGBM** (Efficient Boosting)

### Metrics Calculated for Each Model:

- **Classification Report**: Precision, Recall, F1-Score for each class
- **Specificity** (True Negative Rate): Ability to correctly identify healthy patients
- **Matthews Correlation Coefficient (MCC)**: Balanced metric for imbalanced datasets (-1 to +1)
- **Brier Score**: Probability calibration (lower is better, 0 = perfect)
- **ROC-AUC**: Area under ROC curve (0 to 1, higher is better)
- **PR-AUC**: Area under Precision-Recall curve (better for imbalanced data)

### Example Results (from previous run):

Based on the notebook structure, typical results show:

- **Best Model by MCC**: Usually Logistic Regression or LightGBM
- **Top 2 Models**: Typically Logistic Regression and LightGBM
- **Training Times**: Recorded for efficiency comparison

---

## ğŸ”¬ Statistical Analysis Results

### Hypothesis Testing:

1. **Chi-Square Test**: Gender vs Stroke relationship
   - Tests if there's a statistically significant association
   - P-value interpretation (< 0.05 = significant)

2. **T-Test**: Age difference between stroke and non-stroke patients
   - Tests if stroke patients are significantly older
   - P-value interpretation (< 0.05 = significant difference)

---

## ğŸ“‹ Data Preprocessing Results

### Missing Values:
- **BMI**: Handled with KNNImputer (preserves feature relationships)

### Outlier Treatment:
- **Winsorization**: Applied to `avg_glucose_level` and `bmi`
- Capped at 1st and 99th percentiles (preserves data, reduces outlier impact)

### Feature Engineering:
- **Age_Group**: Young (<45), Middle (45-65), Senior (>65)
- **BMI_Category**: Underweight, Normal, Overweight, Obese
- **Risk_Factor_Count**: Sum of hypertension + heart_disease

---

## ğŸ¯ Key Findings

1. **Class Imbalance**: ~95% Healthy vs ~5% Stroke (severe imbalance)
2. **Best Model**: Identified by highest MCC score
3. **Feature Importance**: Top predictive features identified via tree models and SHAP
4. **Model Calibration**: Brier Score indicates probability reliability

---

## ğŸ“ Output Files Structure

```
project/
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ 01_target_distribution.png
â”‚   â”œâ”€â”€ 02_correlation_heatmap.png
â”‚   â”œâ”€â”€ 03_outliers_before_winsorization.png
â”‚   â”œâ”€â”€ 04_outliers_after_winsorization.png
â”‚   â”œâ”€â”€ 05_violin_plots_numerical_features.png
â”‚   â”œâ”€â”€ 06_roc_auc_curves.png
â”‚   â”œâ”€â”€ 07_precision_recall_curves.png
â”‚   â”œâ”€â”€ 08_confusion_matrices_top2.png
â”‚   â”œâ”€â”€ 09_calibration_curve.png
â”‚   â”œâ”€â”€ 10_feature_importance.png
â”‚   â”œâ”€â”€ 11_shap_summary_bar.png
â”‚   â””â”€â”€ 12_shap_summary_detailed.png
â””â”€â”€ stroke_prediction_full_analysis.ipynb
```

---

## ğŸ’¡ How to View Results

1. **Run the notebook**: Execute all cells sequentially
2. **Check plots folder**: All visualizations are automatically saved
3. **Review console output**: Model metrics and statistical tests are printed
4. **Examine classification reports**: Detailed precision/recall for each model

---

## ğŸ“ Notes for Report Writing

The notebook includes markdown explanations for:
- **Why KNNImputer?** - Preserves feature relationships
- **Why Winsorization?** - Preserves data while handling outliers
- **Why SMOTE?** - Creates synthetic samples for better learning
- **Why MCC?** - Balanced metric for imbalanced datasets
- **Why Brier Score?** - Measures probability calibration

These can be paraphrased for your Methods section.

---

**Last Updated**: Generated by stroke_prediction_full_analysis.ipynb
**All plots saved at**: 300 DPI resolution for publication quality

